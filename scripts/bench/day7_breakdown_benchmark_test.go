package main

import (
	"context"
	"encoding/json"
	"fmt"
	"log"
	"math/rand"
	"os"
	"sync"
	"sync/atomic"
	"time"

	"what_redis_can_do/internal/cache"
	"what_redis_can_do/internal/redisx"

	"github.com/redis/go-redis/v9"
)

// BenchmarkConfig7 åŸºå‡†æµ‹è¯•é…ç½®
type BenchmarkConfig7 struct {
	ConcurrentUsers int           `json:"concurrent_users"`
	TestDuration    time.Duration `json:"test_duration"`
	HotKeyCount     int           `json:"hot_key_count"`
	HotKeyRatio     float64       `json:"hot_key_ratio"`
	CacheExpireTTL  time.Duration `json:"cache_expire_ttl"`
	DBQueryDelay    time.Duration `json:"db_query_delay"`
	RedisAddress    string        `json:"redis_address"`
	OutputFile      string        `json:"output_file"`
}

// BenchmarkResult7 åŸºå‡†æµ‹è¯•ç»“æœ
type BenchmarkResult7 struct {
	Strategy              string              `json:"strategy"`
	Config                BenchmarkConfig7    `json:"config"`
	TotalRequests         int64               `json:"total_requests"`
	SuccessfulRequests    int64               `json:"successful_requests"`
	FailedRequests        int64               `json:"failed_requests"`
	DBQueries             int64               `json:"db_queries"`
	CacheHits             int64               `json:"cache_hits"`
	CacheHitRate          float64             `json:"cache_hit_rate"`
	AvgResponseTime       time.Duration       `json:"avg_response_time"`
	P50ResponseTime       time.Duration       `json:"p50_response_time"`
	P90ResponseTime       time.Duration       `json:"p90_response_time"`
	P95ResponseTime       time.Duration       `json:"p95_response_time"`
	P99ResponseTime       time.Duration       `json:"p99_response_time"`
	MaxResponseTime       time.Duration       `json:"max_response_time"`
	QPS                   float64             `json:"qps"`
	SingleflightStats     *SingleflightStats  `json:"singleflight_stats,omitempty"`
	LogicalExpireStats    *LogicalExpireStats `json:"logical_expire_stats,omitempty"`
	ResponseTimeHistogram map[string]int64    `json:"response_time_histogram"`
	Timestamp             time.Time           `json:"timestamp"`
}

// SingleflightStats å•é£ç»Ÿè®¡
type SingleflightStats struct {
	Hits     int64 `json:"hits"`
	Misses   int64 `json:"misses"`
	Timeouts int64 `json:"timeouts"`
	Errors   int64 `json:"errors"`
}

// LogicalExpireStats é€»è¾‘è¿‡æœŸç»Ÿè®¡
type LogicalExpireStats struct {
	Hits         int64 `json:"hits"`
	ExpiredHits  int64 `json:"expired_hits"`
	RefreshCount int64 `json:"refresh_count"`
	ExpiredCount int64 `json:"expired_count"`
}

// MockDataService æ¨¡æ‹Ÿæ•°æ®æœåŠ¡
type MockDataService struct {
	queryCount int64
	queryDelay time.Duration
	data       map[string]interface{}
	mu         sync.RWMutex
}

// NewMockDataService åˆ›å»ºæ¨¡æ‹Ÿæ•°æ®æœåŠ¡
func NewMockDataService(queryDelay time.Duration) *MockDataService {
	data := make(map[string]interface{})

	// åˆå§‹åŒ–æµ‹è¯•æ•°æ®
	for i := 1; i <= 10000; i++ {
		key := fmt.Sprintf("item:%d", i)
		data[key] = map[string]interface{}{
			"id":    i,
			"name":  fmt.Sprintf("Item %d", i),
			"value": rand.Float64() * 1000,
			"tags":  []string{fmt.Sprintf("tag%d", i%10), fmt.Sprintf("category%d", i%5)},
		}
	}

	return &MockDataService{
		queryDelay: queryDelay,
		data:       data,
	}
}

// Query æŸ¥è¯¢æ•°æ®
func (mds *MockDataService) Query(ctx context.Context, key string) (interface{}, error) {
	atomic.AddInt64(&mds.queryCount, 1)

	// æ¨¡æ‹ŸæŸ¥è¯¢å»¶è¿Ÿ
	select {
	case <-time.After(mds.queryDelay):
	case <-ctx.Done():
		return nil, ctx.Err()
	}

	mds.mu.RLock()
	data, exists := mds.data[key]
	mds.mu.RUnlock()

	if !exists {
		return nil, fmt.Errorf("data not found: %s", key)
	}

	return data, nil
}

// GetQueryCount è·å–æŸ¥è¯¢æ¬¡æ•°
func (mds *MockDataService) GetQueryCount() int64 {
	return atomic.LoadInt64(&mds.queryCount)
}

// ResetQueryCount é‡ç½®æŸ¥è¯¢è®¡æ•°
func (mds *MockDataService) ResetQueryCount() {
	atomic.StoreInt64(&mds.queryCount, 0)
}

// BenchmarkRunner åŸºå‡†æµ‹è¯•è¿è¡Œå™¨
type BenchmarkRunner struct {
	config      BenchmarkConfig7
	dataService *MockDataService
	client      redis.Cmdable
}

// NewBenchmarkRunner åˆ›å»ºåŸºå‡†æµ‹è¯•è¿è¡Œå™¨
func NewBenchmarkRunner(config BenchmarkConfig7) (*BenchmarkRunner, error) {
	// åˆ›å»ºRediså®¢æˆ·ç«¯
	client, err := redisx.NewClient(&redisx.Config{
		Addr:     config.RedisAddress,
		Password: "",
		DB:       0,
		PoolSize: config.ConcurrentUsers * 2,
	})
	if err != nil {
		return nil, fmt.Errorf("failed to create Redis client: %w", err)
	}

	// åˆ›å»ºæ•°æ®æœåŠ¡
	dataService := NewMockDataService(config.DBQueryDelay)

	return &BenchmarkRunner{
		config:      config,
		dataService: dataService,
		client:      client,
	}, nil
}

// RunBenchmark è¿è¡ŒåŸºå‡†æµ‹è¯•
func (br *BenchmarkRunner) RunBenchmark() (*BenchmarkResult7, error) {
	strategies := []string{"no_protection", "singleflight", "logical_expire"}
	var results []*BenchmarkResult7

	for _, strategy := range strategies {
		fmt.Printf("ğŸ§ª Running benchmark for strategy: %s\n", strategy)

		// æ¸…ç†ç¼“å­˜
		br.client.FlushDB(context.Background())
		br.dataService.ResetQueryCount()

		result, err := br.runSingleStrategy(strategy)
		if err != nil {
			log.Printf("Error running strategy %s: %v", strategy, err)
			continue
		}

		results = append(results, result)

		// æ‰“å°ç»“æœ
		br.printResult(result)
		fmt.Println()

		// ä¼‘æ¯ä¸€ä¸‹
		time.Sleep(2 * time.Second)
	}

	// ä¿å­˜ç»“æœåˆ°æ–‡ä»¶
	if br.config.OutputFile != "" {
		err := br.saveResults(results)
		if err != nil {
			log.Printf("Error saving results: %v", err)
		}
	}

	// æ‰“å°å¯¹æ¯”æŠ¥å‘Š
	br.printComparisonReport(results)

	return nil, nil
}

// runSingleStrategy è¿è¡Œå•ä¸ªç­–ç•¥çš„æµ‹è¯•
func (br *BenchmarkRunner) runSingleStrategy(strategy string) (*BenchmarkResult7, error) {
	// åˆ›å»ºç¼“å­˜ç»„ä»¶
	redisCache := cache.NewRedisCache(br.client, cache.DefaultCacheAsideOptions())

	var breakdownProtection *cache.BreakdownProtection

	switch strategy {
	case "singleflight":
		opts := cache.DefaultBreakdownOptions()
		opts.EnableSingleflight = true
		opts.EnableLogicalExpire = false
		breakdownProtection = cache.NewBreakdownProtection(redisCache, opts)
	case "logical_expire":
		opts := cache.DefaultBreakdownOptions()
		opts.EnableSingleflight = false
		opts.EnableLogicalExpire = true
		breakdownProtection = cache.NewBreakdownProtection(redisCache, opts)
	}

	// åˆ›å»ºæ•°æ®åŠ è½½å‡½æ•°
	loader := func(ctx context.Context, key string) (interface{}, error) {
		return br.dataService.Query(ctx, key)
	}

	// ç»Ÿè®¡å˜é‡
	var totalRequests int64
	var successfulRequests int64
	var failedRequests int64
	var responseTimes []time.Duration
	var responseTimeMu sync.Mutex

	// å¯åŠ¨å¹¶å‘æµ‹è¯•
	ctx, cancel := context.WithTimeout(context.Background(), br.config.TestDuration)
	defer cancel()

	var wg sync.WaitGroup
	startTime := time.Now()

	for i := 0; i < br.config.ConcurrentUsers; i++ {
		wg.Add(1)
		go func(workerID int) {
			defer wg.Done()

			for {
				select {
				case <-ctx.Done():
					return
				default:
					// ç”ŸæˆKey
					key := br.generateKey()

					requestStart := time.Now()
					atomic.AddInt64(&totalRequests, 1)

					var result interface{}
					var err error

					if breakdownProtection != nil {
						// ä½¿ç”¨å‡»ç©¿é˜²æŠ¤
						err = breakdownProtection.GetOrLoad(context.Background(), key, &result, loader)
					} else {
						// ç›´æ¥ä½¿ç”¨ç¼“å­˜
						err = redisCache.Get(context.Background(), key, &result)
						if err == cache.ErrCacheMiss {
							// ç¼“å­˜æœªå‘½ä¸­ï¼ŒæŸ¥è¯¢æ•°æ®æº
							result, err = br.dataService.Query(context.Background(), key)
							if err == nil {
								// å†™å…¥ç¼“å­˜
								redisCache.Set(context.Background(), key, result, br.config.CacheExpireTTL)
							}
						}
					}

					responseTime := time.Since(requestStart)

					responseTimeMu.Lock()
					responseTimes = append(responseTimes, responseTime)
					responseTimeMu.Unlock()

					if err != nil {
						atomic.AddInt64(&failedRequests, 1)
					} else {
						atomic.AddInt64(&successfulRequests, 1)
					}

					// éšæœºå»¶è¿Ÿ
					time.Sleep(time.Duration(rand.Intn(10)) * time.Millisecond)
				}
			}
		}(i)
	}

	wg.Wait()

	actualDuration := time.Since(startTime)

	// è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
	dbQueries := br.dataService.GetQueryCount()
	cacheHits := successfulRequests - dbQueries
	cacheHitRate := float64(cacheHits) / float64(successfulRequests) * 100
	qps := float64(totalRequests) / actualDuration.Seconds()

	// è®¡ç®—å“åº”æ—¶é—´ç»Ÿè®¡
	avgResponseTime, p50, p90, p95, p99, maxResponseTime := br.calculateResponseTimeStats(responseTimes)

	// åˆ›å»ºå“åº”æ—¶é—´ç›´æ–¹å›¾
	histogram := br.createResponseTimeHistogram(responseTimes)

	result := &BenchmarkResult7{
		Strategy:              strategy,
		Config:                br.config,
		TotalRequests:         totalRequests,
		SuccessfulRequests:    successfulRequests,
		FailedRequests:        failedRequests,
		DBQueries:             dbQueries,
		CacheHits:             cacheHits,
		CacheHitRate:          cacheHitRate,
		AvgResponseTime:       avgResponseTime,
		P50ResponseTime:       p50,
		P90ResponseTime:       p90,
		P95ResponseTime:       p95,
		P99ResponseTime:       p99,
		MaxResponseTime:       maxResponseTime,
		QPS:                   qps,
		ResponseTimeHistogram: histogram,
		Timestamp:             time.Now(),
	}

	// è·å–å‡»ç©¿é˜²æŠ¤ç»Ÿè®¡
	if breakdownProtection != nil {
		stats := breakdownProtection.GetStats()

		if strategy == "singleflight" {
			result.SingleflightStats = &SingleflightStats{
				Hits:     stats.SingleflightHits,
				Misses:   stats.SingleflightMisses,
				Timeouts: stats.SingleflightTimeouts,
				Errors:   stats.SingleflightErrors,
			}
		} else if strategy == "logical_expire" {
			result.LogicalExpireStats = &LogicalExpireStats{
				Hits:         stats.LogicalExpireHits,
				ExpiredHits:  stats.LogicalExpireExpired,
				RefreshCount: stats.LogicalExpireRefresh,
				ExpiredCount: stats.LogicalExpireExpired,
			}
		}
	}

	return result, nil
}

// generateKey ç”Ÿæˆæµ‹è¯•Key
func (br *BenchmarkRunner) generateKey() string {
	if rand.Float64() < br.config.HotKeyRatio {
		// çƒ­ç‚¹Key
		id := rand.Intn(br.config.HotKeyCount) + 1
		return fmt.Sprintf("item:%d", id)
	} else {
		// æ™®é€šKey
		id := rand.Intn(10000-br.config.HotKeyCount) + br.config.HotKeyCount + 1
		return fmt.Sprintf("item:%d", id)
	}
}

// calculateResponseTimeStats è®¡ç®—å“åº”æ—¶é—´ç»Ÿè®¡
func (br *BenchmarkRunner) calculateResponseTimeStats(responseTimes []time.Duration) (avg, p50, p90, p95, p99, max time.Duration) {
	if len(responseTimes) == 0 {
		return 0, 0, 0, 0, 0, 0
	}

	// æ’åº
	for i := 0; i < len(responseTimes)-1; i++ {
		for j := 0; j < len(responseTimes)-i-1; j++ {
			if responseTimes[j] > responseTimes[j+1] {
				responseTimes[j], responseTimes[j+1] = responseTimes[j+1], responseTimes[j]
			}
		}
	}

	// è®¡ç®—å„ç§ç»Ÿè®¡å€¼
	var total time.Duration
	for _, rt := range responseTimes {
		total += rt
	}
	avg = total / time.Duration(len(responseTimes))

	p50 = responseTimes[int(float64(len(responseTimes))*0.5)]
	p90 = responseTimes[int(float64(len(responseTimes))*0.9)]
	p95 = responseTimes[int(float64(len(responseTimes))*0.95)]
	p99 = responseTimes[int(float64(len(responseTimes))*0.99)]
	max = responseTimes[len(responseTimes)-1]

	return avg, p50, p90, p95, p99, max
}

// createResponseTimeHistogram åˆ›å»ºå“åº”æ—¶é—´ç›´æ–¹å›¾
func (br *BenchmarkRunner) createResponseTimeHistogram(responseTimes []time.Duration) map[string]int64 {
	histogram := make(map[string]int64)

	buckets := []time.Duration{
		1 * time.Millisecond,
		5 * time.Millisecond,
		10 * time.Millisecond,
		50 * time.Millisecond,
		100 * time.Millisecond,
		500 * time.Millisecond,
		1 * time.Second,
		5 * time.Second,
	}

	for _, rt := range responseTimes {
		for i, bucket := range buckets {
			if rt <= bucket {
				key := fmt.Sprintf("â‰¤%v", bucket)
				histogram[key]++
				break
			}
			if i == len(buckets)-1 {
				histogram[">5s"]++
			}
		}
	}

	return histogram
}

// printResult æ‰“å°ç»“æœ
func (br *BenchmarkRunner) printResult(result *BenchmarkResult7) {
	fmt.Printf("ğŸ“Š Strategy: %s\n", result.Strategy)
	fmt.Printf("   Total Requests: %d\n", result.TotalRequests)
	fmt.Printf("   Successful: %d\n", result.SuccessfulRequests)
	fmt.Printf("   Failed: %d\n", result.FailedRequests)
	fmt.Printf("   DB Queries: %d\n", result.DBQueries)
	fmt.Printf("   Cache Hit Rate: %.2f%%\n", result.CacheHitRate)
	fmt.Printf("   QPS: %.2f\n", result.QPS)
	fmt.Printf("   Avg Response Time: %v\n", result.AvgResponseTime)
	fmt.Printf("   P50: %v, P90: %v, P95: %v, P99: %v\n",
		result.P50ResponseTime, result.P90ResponseTime, result.P95ResponseTime, result.P99ResponseTime)

	if result.SingleflightStats != nil {
		fmt.Printf("   Singleflight - Hits: %d, Misses: %d\n",
			result.SingleflightStats.Hits, result.SingleflightStats.Misses)
	}

	if result.LogicalExpireStats != nil {
		fmt.Printf("   Logical Expire - Hits: %d, Expired Hits: %d\n",
			result.LogicalExpireStats.Hits, result.LogicalExpireStats.ExpiredHits)
	}
}

// printComparisonReport æ‰“å°å¯¹æ¯”æŠ¥å‘Š
func (br *BenchmarkRunner) printComparisonReport(results []*BenchmarkResult7) {
	fmt.Println("ğŸ“ˆ Breakdown Protection Benchmark Comparison Report")
	fmt.Println("=" + fmt.Sprintf("%*s", 80, "="))

	fmt.Printf("%-20s %-10s %-12s %-12s %-12s %-12s %-10s\n",
		"Strategy", "QPS", "Cache Hit%", "DB Queries", "Avg Resp", "P99 Resp", "Errors")
	fmt.Println("-" + fmt.Sprintf("%*s", 100, "-"))

	for _, result := range results {
		fmt.Printf("%-20s %-10.0f %-12.2f %-12d %-12v %-12v %-10d\n",
			result.Strategy,
			result.QPS,
			result.CacheHitRate,
			result.DBQueries,
			result.AvgResponseTime,
			result.P99ResponseTime,
			result.FailedRequests,
		)
	}

	fmt.Println()

	// åˆ†ææ”¹è¿›æ•ˆæœ
	if len(results) >= 2 {
		baseline := results[0] // æ— é˜²æŠ¤ä½œä¸ºåŸºçº¿

		for i := 1; i < len(results); i++ {
			result := results[i]

			dbReduction := float64(baseline.DBQueries-result.DBQueries) / float64(baseline.DBQueries) * 100
			qpsImprovement := (result.QPS - baseline.QPS) / baseline.QPS * 100
			responseImprovement := float64(baseline.AvgResponseTime-result.AvgResponseTime) / float64(baseline.AvgResponseTime) * 100

			fmt.Printf("ğŸ¯ %s vs %s:\n", result.Strategy, baseline.Strategy)
			fmt.Printf("   DB queries reduced: %.2f%%\n", dbReduction)
			fmt.Printf("   QPS improvement: %.2f%%\n", qpsImprovement)
			fmt.Printf("   Avg response time improvement: %.2f%%\n", responseImprovement)
			fmt.Println()
		}
	}
}

// saveResults ä¿å­˜ç»“æœåˆ°æ–‡ä»¶
func (br *BenchmarkRunner) saveResults(results []*BenchmarkResult7) error {
	data, err := json.MarshalIndent(map[string]interface{}{
		"benchmark_config": br.config,
		"results":          results,
		"summary": map[string]interface{}{
			"timestamp":         time.Now(),
			"strategies_tested": len(results),
		},
	}, "", "  ")
	if err != nil {
		return fmt.Errorf("marshal results: %w", err)
	}

	return os.WriteFile(br.config.OutputFile, data, 0644)
}

func main7() {
	config := BenchmarkConfig7{
		ConcurrentUsers: 50,
		TestDuration:    30 * time.Second,
		HotKeyCount:     10,  // å‰10ä¸ªKeyä½œä¸ºçƒ­ç‚¹
		HotKeyRatio:     0.8, // 80%çš„è¯·æ±‚è®¿é—®çƒ­ç‚¹Key
		CacheExpireTTL:  10 * time.Minute,
		DBQueryDelay:    50 * time.Millisecond,
		RedisAddress:    "localhost:6379",
		OutputFile:      "benchmark_results/breakdown_benchmark_" + time.Now().Format("20060102_150405") + ".json",
	}

	// åˆ›å»ºè¾“å‡ºç›®å½•
	os.MkdirAll("benchmark_results", 0755)

	runner, err := NewBenchmarkRunner(config)
	if err != nil {
		log.Fatalf("Failed to create benchmark runner: %v", err)
	}

	fmt.Println("ğŸš€ Starting Cache Breakdown Protection Benchmark")
	fmt.Printf("   Concurrent Users: %d\n", config.ConcurrentUsers)
	fmt.Printf("   Test Duration: %v\n", config.TestDuration)
	fmt.Printf("   Hot Key Ratio: %.1f%%\n", config.HotKeyRatio*100)
	fmt.Printf("   DB Query Delay: %v\n", config.DBQueryDelay)
	fmt.Println()

	_, err = runner.RunBenchmark()
	if err != nil {
		log.Fatalf("Benchmark failed: %v", err)
	}

	fmt.Println("âœ… Benchmark completed successfully!")
	if config.OutputFile != "" {
		fmt.Printf("ğŸ“ Results saved to: %s\n", config.OutputFile)
	}
}
