# Redisç¼“å­˜æœ€ä½³å®è·µæŒ‡å—

## ğŸ¯ æ¦‚è¿°

æœ¬æŒ‡å—åŸºäºDay 5çš„å­¦ä¹ æˆæœï¼Œæä¾›Redisç¼“å­˜åœ¨ç”Ÿäº§ç¯å¢ƒä¸­çš„æœ€ä½³å®è·µï¼ŒåŒ…æ‹¬æ¨¡å¼é€‰æ‹©ã€é…ç½®ä¼˜åŒ–ã€ç›‘æ§å‘Šè­¦ç­‰ã€‚

## ğŸ”§ ç¼“å­˜æ¨¡å¼é€‰æ‹©æŒ‡å—

### 1. Cache-Asideï¼ˆæ—è·¯ç¼“å­˜ï¼‰

**é€‚ç”¨åœºæ™¯ï¼š**
- è¯»å¤šå†™å°‘çš„ä¸šåŠ¡åœºæ™¯
- å…è®¸çŸ­æš‚æ•°æ®ä¸ä¸€è‡´
- éœ€è¦åº”ç”¨å®Œå…¨æ§åˆ¶ç¼“å­˜é€»è¾‘

**é…ç½®ç¤ºä¾‹ï¼š**
```go
userCache := cache.NewCacheAside(redisCache, &cache.CacheAsideOptions{
    TTL:           2 * time.Hour,     // ç”¨æˆ·ä¿¡æ¯TTL
    TTLJitter:     0.1,               // 10%æŠ–åŠ¨é˜²é›ªå´©
    EmptyValueTTL: 5 * time.Minute,   // ç©ºå€¼ç¼“å­˜TTL
    Serializer:    &cache.JSONSerializer{},
    EnableMetrics: true,
    Namespace:     "user",
})
```

**ä½¿ç”¨æ¨¡å¼ï¼š**
```go
func GetUser(ctx context.Context, userID int) (*User, error) {
    key := fmt.Sprintf("profile:%d", userID)
    var user User
    
    err := userCache.GetOrLoad(ctx, key, &user, func(ctx context.Context, key string) (interface{}, error) {
        return userService.LoadFromDB(ctx, userID)
    })
    
    return &user, err
}

func UpdateUser(ctx context.Context, user *User) error {
    // å…ˆæ›´æ–°æ•°æ®æº
    if err := userService.UpdateDB(ctx, user); err != nil {
        return err
    }
    
    // åˆ é™¤ç¼“å­˜ï¼Œä¸‹æ¬¡è¯»å–æ—¶ä¼šé‡æ–°åŠ è½½
    key := fmt.Sprintf("profile:%d", user.ID)
    userCache.Del(ctx, key)
    
    return nil
}
```

### 2. Write-Throughï¼ˆå†™ç©¿é€ï¼‰

**é€‚ç”¨åœºæ™¯ï¼š**
- éœ€è¦å¼ºæ•°æ®ä¸€è‡´æ€§
- å†™å…¥é¢‘ç‡ä¸é«˜
- èƒ½å®¹å¿å†™å…¥å»¶è¿Ÿå¢åŠ 

**é…ç½®ç¤ºä¾‹ï¼š**
```go
configCache := cache.NewWriteThroughCache(redisCache, 
    func(ctx context.Context, key string, value interface{}) error {
        return configService.SaveToDB(ctx, key, value)
    }, 
    &cache.CacheAsideOptions{
        TTL:        24 * time.Hour,  // é…ç½®ä¿¡æ¯TTLè¾ƒé•¿
        Serializer: &cache.JSONSerializer{},
        Namespace:  "config",
    })
```

### 3. Write-Behindï¼ˆå†™å›ï¼‰

**é€‚ç”¨åœºæ™¯ï¼š**
- å†™å…¥å¯†é›†å‹åœºæ™¯
- å¯ä»¥å®¹å¿æ•°æ®ä¸¢å¤±é£é™©
- éœ€è¦é«˜å†™å…¥æ€§èƒ½

**é…ç½®ç¤ºä¾‹ï¼š**
```go
logCache := cache.NewWriteBehindCache(redisCache,
    func(ctx context.Context, key string, value interface{}) error {
        return logService.BatchWrite(ctx, key, value)
    },
    &cache.WriteBehindOptions{
        CacheAsideOptions: &cache.CacheAsideOptions{
            TTL:        1 * time.Hour,
            Serializer: &cache.JSONSerializer{},
            Namespace:  "logs",
        },
        BufferSize:    1000,              // ç¼“å†²åŒºå¤§å°
        FlushInterval: 5 * time.Second,   // åˆ·æ–°é—´éš”
        BatchSize:     100,               // æ‰¹é‡å¤§å°
        MaxRetries:    3,                 // æœ€å¤§é‡è¯•æ¬¡æ•°
    })
```

## âš™ï¸ TTLè®¾è®¡ç­–ç•¥

### 1. åˆ†å±‚TTLé…ç½®

```go
func GetTTLByDataType(dataType string) time.Duration {
    switch dataType {
    case "user_profile":
        return 2 * time.Hour      // ç”¨æˆ·ä¿¡æ¯å˜åŒ–ä¸é¢‘ç¹
    case "product_info":
        return 1 * time.Hour      // å•†å“ä¿¡æ¯å¯èƒ½æ›´æ–°
    case "inventory":
        return 10 * time.Minute   // åº“å­˜å˜åŒ–é¢‘ç¹
    case "price":
        return 30 * time.Minute   // ä»·æ ¼å¯èƒ½è°ƒæ•´
    case "hot_data":
        return 4 * time.Hour      // çƒ­ç‚¹æ•°æ®ä¿å­˜æ›´ä¹…
    case "session":
        return 30 * time.Minute   // ç”¨æˆ·ä¼šè¯
    case "verification_code":
        return 5 * time.Minute    // éªŒè¯ç çŸ­æœŸæœ‰æ•ˆ
    case "temp_cache":
        return 1 * time.Minute    // ä¸´æ—¶ç¼“å­˜
    default:
        return 1 * time.Hour      // é»˜è®¤TTL
    }
}
```

### 2. åŠ¨æ€TTLè°ƒæ•´

```go
func CalculateDynamicTTL(baseType string, accessFrequency int, dataSize int) time.Duration {
    baseTTL := GetTTLByDataType(baseType)
    
    // æ ¹æ®è®¿é—®é¢‘ç‡è°ƒæ•´
    if accessFrequency > 1000 {
        baseTTL = baseTTL * 2  // çƒ­ç‚¹æ•°æ®å»¶é•¿TTL
    } else if accessFrequency < 10 {
        baseTTL = baseTTL / 2  // å†·æ•°æ®ç¼©çŸ­TTL
    }
    
    // æ ¹æ®æ•°æ®å¤§å°è°ƒæ•´
    if dataSize > 1024*1024 { // å¤§äº1MB
        baseTTL = baseTTL / 2  // å¤§æ•°æ®ç¼©çŸ­TTL
    }
    
    return baseTTL
}
```

### 3. TTLæŠ–åŠ¨é…ç½®

```go
// æ ¹æ®æ•°æ®é‡å’Œé‡è¦æ€§é…ç½®æŠ–åŠ¨
func GetJitterByDataVolume(expectedKeys int) float64 {
    switch {
    case expectedKeys > 100000:
        return 0.3  // å¤§é‡æ•°æ®éœ€è¦æ›´å¤§æŠ–åŠ¨
    case expectedKeys > 10000:
        return 0.2  // ä¸­é‡æ•°æ®ä¸­ç­‰æŠ–åŠ¨
    case expectedKeys > 1000:
        return 0.1  // å°‘é‡æ•°æ®å°æŠ–åŠ¨
    default:
        return 0.05 // æå°‘æ•°æ®æœ€å°æŠ–åŠ¨
    }
}
```

## ğŸ”‘ Keyè®¾è®¡è§„èŒƒ

### 1. å‘½åè§„èŒƒ

```go
// æ¨èæ ¼å¼ï¼šnamespace:service:type:id:version
const (
    UserProfileKey = "app:user:profile:%d:v1"
    OrderDetailKey = "app:order:detail:%s:v2"
    ProductInfoKey = "app:product:info:%d:v1"
    SessionKey     = "app:session:%s:v1"
)

func BuildUserKey(userID int) string {
    return fmt.Sprintf(UserProfileKey, userID)
}
```

### 2. Keyé•¿åº¦ä¼˜åŒ–

```go
// ä½¿ç”¨çŸ­è€Œæœ‰æ„ä¹‰çš„ç¼©å†™
const (
    // å¥½çš„ä¾‹å­
    UserKey  = "u:%d"           // ç”¨æˆ·
    OrderKey = "o:%s"           // è®¢å•  
    ProdKey  = "p:%d"           // å•†å“
    
    // é¿å…è¿‡é•¿çš„key
    // "application:user:profile:detailed:information:%d" // å¤ªé•¿
)
```

### 3. æ‰¹é‡Keyè®¾è®¡

```go
// æ”¯æŒæ‰¹é‡æ“ä½œçš„Keyè®¾è®¡
func BuildBatchUserKeys(userIDs []int) []string {
    keys := make([]string, len(userIDs))
    for i, id := range userIDs {
        keys[i] = fmt.Sprintf("u:%d", id)
    }
    return keys
}
```

## ğŸ“Š ç›‘æ§ä¸å‘Šè­¦

### 1. å…³é”®æŒ‡æ ‡ç›‘æ§

```go
type CacheMonitor struct {
    cache   *cache.RedisCache
    alerter Alerter
}

func (m *CacheMonitor) CheckHealth() {
    stats := m.cache.GetStats()
    
    // å‘½ä¸­ç‡ç›‘æ§
    if stats.HitRate < 0.8 {
        m.alerter.Alert("LOW_HIT_RATE", map[string]interface{}{
            "hit_rate": stats.HitRate,
            "threshold": 0.8,
        })
    }
    
    // å»¶è¿Ÿç›‘æ§
    if stats.AvgGetLatencyUs > 5000 { // 5ms
        m.alerter.Alert("HIGH_LATENCY", map[string]interface{}{
            "latency_us": stats.AvgGetLatencyUs,
            "threshold": 5000,
        })
    }
    
    // é”™è¯¯ç‡ç›‘æ§
    totalOps := stats.Hits + stats.Misses
    if totalOps > 0 {
        errorRate := float64(stats.GetErrors) / float64(totalOps)
        if errorRate > 0.01 { // 1%
            m.alerter.Alert("HIGH_ERROR_RATE", map[string]interface{}{
                "error_rate": errorRate,
                "threshold": 0.01,
            })
        }
    }
}
```

### 2. æ€§èƒ½åŸºå‡†æµ‹è¯•

```go
func BenchmarkCachePerformance(b *testing.B) {
    cache := setupTestCache()
    ctx := context.Background()
    
    // å†™å…¥æ€§èƒ½æµ‹è¯•
    b.Run("Set", func(b *testing.B) {
        for i := 0; i < b.N; i++ {
            key := fmt.Sprintf("bench:set:%d", i)
            cache.Set(ctx, key, "test_value", time.Hour)
        }
    })
    
    // è¯»å–æ€§èƒ½æµ‹è¯•
    b.Run("Get", func(b *testing.B) {
        // é¢„å¡«å……æ•°æ®
        for i := 0; i < 1000; i++ {
            key := fmt.Sprintf("bench:get:%d", i)
            cache.Set(ctx, key, "test_value", time.Hour)
        }
        
        b.ResetTimer()
        for i := 0; i < b.N; i++ {
            key := fmt.Sprintf("bench:get:%d", i%1000)
            var value string
            cache.Get(ctx, key, &value)
        }
    })
}
```

## ğŸš¨ æ•…éšœå¤„ç†ä¸å®¹é”™

### 1. ç¼“å­˜é™çº§ç­–ç•¥

```go
type CacheWithFallback struct {
    primary   cache.Cache
    secondary cache.Cache  // æœ¬åœ°ç¼“å­˜
    db        DataSource
}

func (c *CacheWithFallback) Get(ctx context.Context, key string, dest interface{}) error {
    // å°è¯•ä¸»ç¼“å­˜
    err := c.primary.Get(ctx, key, dest)
    if err == nil {
        return nil
    }
    
    // ä¸»ç¼“å­˜å¤±è´¥ï¼Œå°è¯•äºŒçº§ç¼“å­˜
    if c.secondary != nil {
        err = c.secondary.Get(ctx, key, dest)
        if err == nil {
            // å¼‚æ­¥å›å†™ä¸»ç¼“å­˜
            go c.asyncWriteBack(key, dest)
            return nil
        }
    }
    
    // ç¼“å­˜å…¨éƒ¨å¤±è´¥ï¼Œç›´æ¥æŸ¥è¯¢æ•°æ®æº
    return c.loadFromDataSource(ctx, key, dest)
}

func (c *CacheWithFallback) asyncWriteBack(key string, value interface{}) {
    ctx, cancel := context.WithTimeout(context.Background(), 1*time.Second)
    defer cancel()
    
    c.primary.Set(ctx, key, value, time.Hour)
}
```

### 2. ç†”æ–­å™¨æ¨¡å¼

```go
type CircuitBreakerCache struct {
    cache   cache.Cache
    breaker *CircuitBreaker
}

func (c *CircuitBreakerCache) Get(ctx context.Context, key string, dest interface{}) error {
    if c.breaker.IsOpen() {
        return ErrCacheUnavailable
    }
    
    err := c.cache.Get(ctx, key, dest)
    if err != nil {
        c.breaker.RecordFailure()
        return err
    }
    
    c.breaker.RecordSuccess()
    return nil
}
```

### 3. è¶…æ—¶æ§åˆ¶

```go
func GetWithTimeout(ctx context.Context, cache cache.Cache, key string, dest interface{}, timeout time.Duration) error {
    ctx, cancel := context.WithTimeout(ctx, timeout)
    defer cancel()
    
    done := make(chan error, 1)
    go func() {
        done <- cache.Get(ctx, key, dest)
    }()
    
    select {
    case err := <-done:
        return err
    case <-ctx.Done():
        return ctx.Err()
    }
}
```

## âš¡ æ€§èƒ½ä¼˜åŒ–æŠ€å·§

### 1. è¿æ¥æ± é…ç½®

```go
// ç”Ÿäº§ç¯å¢ƒæ¨èé…ç½®
func ProductionRedisConfig() *redisx.Config {
    return &redisx.Config{
        Addr:     "redis-cluster.internal:6379",
        Password: getRedisPassword(),
        
        // è¿æ¥æ± é…ç½®
        PoolSize:        100,              // æ ¹æ®å¹¶å‘é‡è°ƒæ•´
        MinIdleConns:    20,               // ä¿æŒæœ€å°è¿æ¥
        MaxIdleConns:    50,               // æœ€å¤§ç©ºé—²è¿æ¥
        ConnMaxIdleTime: 30 * time.Minute, // ç©ºé—²è¿æ¥è¶…æ—¶
        ConnMaxLifetime: 2 * time.Hour,    // è¿æ¥æœ€å¤§ç”Ÿå‘½å‘¨æœŸ
        
        // è¶…æ—¶é…ç½®
        DialTimeout:  5 * time.Second,     // è¿æ¥è¶…æ—¶
        ReadTimeout:  3 * time.Second,     // è¯»è¶…æ—¶
        WriteTimeout: 3 * time.Second,     // å†™è¶…æ—¶
        
        // é‡è¯•é…ç½®
        MaxRetries:      3,                          // æœ€å¤§é‡è¯•æ¬¡æ•°
        MinRetryBackoff: 8 * time.Millisecond,      // æœ€å°é‡è¯•é—´éš”
        MaxRetryBackoff: 512 * time.Millisecond,    // æœ€å¤§é‡è¯•é—´éš”
        
        EnableMetrics: true,
    }
}
```

### 2. åºåˆ—åŒ–ä¼˜åŒ–

```go
// æ ¹æ®æ•°æ®ç±»å‹é€‰æ‹©æœ€ä½³åºåˆ—åŒ–å™¨
func GetOptiMalSerializer(dataType reflect.Type) cache.Serializer {
    switch dataType.Kind() {
    case reflect.String:
        return &cache.StringSerializer{}  // å­—ç¬¦ä¸²ç›´æ¥å­˜å‚¨
    case reflect.Int, reflect.Int64, reflect.Float64:
        return &cache.StringSerializer{}  // æ•°å­—è½¬å­—ç¬¦ä¸²å­˜å‚¨
    default:
        return &cache.JSONSerializer{}    // å¤æ‚å¯¹è±¡ç”¨JSON
    }
}
```

### 3. æ‰¹é‡æ“ä½œä¼˜åŒ–

```go
func BatchGet(ctx context.Context, cache *cache.RedisCache, keys []string) (map[string]interface{}, error) {
    // ä½¿ç”¨Pipelineæ‰¹é‡è·å–
    pipe := cache.Pipeline()
    cmds := make(map[string]*redis.StringCmd)
    
    for _, key := range keys {
        cmds[key] = pipe.Get(ctx, key)
    }
    
    _, err := pipe.Exec(ctx)
    if err != nil && err != redis.Nil {
        return nil, err
    }
    
    results := make(map[string]interface{})
    for key, cmd := range cmds {
        if cmd.Err() == nil {
            results[key] = cmd.Val()
        }
    }
    
    return results, nil
}
```

## ğŸ§ª æµ‹è¯•ç­–ç•¥

### 1. å•å…ƒæµ‹è¯•

```go
func TestCacheOperations(t *testing.T) {
    // ä½¿ç”¨å†…å­˜Redisæˆ–Mockè¿›è¡Œæµ‹è¯•
    cache := setupTestCache(t)
    ctx := context.Background()
    
    tests := []struct {
        name string
        key  string
        value interface{}
        ttl  time.Duration
    }{
        {"string", "test:string", "hello", time.Minute},
        {"number", "test:number", 42, time.Minute},
        {"object", "test:object", map[string]string{"key": "value"}, time.Minute},
    }
    
    for _, tt := range tests {
        t.Run(tt.name, func(t *testing.T) {
            // è®¾ç½®ç¼“å­˜
            err := cache.Set(ctx, tt.key, tt.value, tt.ttl)
            assert.NoError(t, err)
            
            // è·å–ç¼“å­˜
            var result interface{}
            err = cache.Get(ctx, tt.key, &result)
            assert.NoError(t, err)
            assert.Equal(t, tt.value, result)
        })
    }
}
```

### 2. é›†æˆæµ‹è¯•

```go
func TestCacheIntegration(t *testing.T) {
    if testing.Short() {
        t.Skip("è·³è¿‡é›†æˆæµ‹è¯•")
    }
    
    // è¿æ¥çœŸå®Rediså®ä¾‹
    client := setupRealRedis(t)
    cache := cache.NewRedisCache(client, cache.DefaultCacheAsideOptions())
    
    // æµ‹è¯•å®Œæ•´ä¸šåŠ¡æµç¨‹
    testBusinessFlow(t, cache)
}
```

### 3. å‹åŠ›æµ‹è¯•

```go
func TestCacheConcurrency(t *testing.T) {
    cache := setupTestCache(t)
    ctx := context.Background()
    
    const numGoroutines = 100
    const numOperations = 1000
    
    var wg sync.WaitGroup
    
    // å¹¶å‘å†™å…¥æµ‹è¯•
    for i := 0; i < numGoroutines; i++ {
        wg.Add(1)
        go func(id int) {
            defer wg.Done()
            for j := 0; j < numOperations; j++ {
                key := fmt.Sprintf("test:%d:%d", id, j)
                cache.Set(ctx, key, fmt.Sprintf("value-%d-%d", id, j), time.Minute)
            }
        }(i)
    }
    
    wg.Wait()
    
    // éªŒè¯æ•°æ®å®Œæ•´æ€§
    stats := cache.GetStats()
    expectedSets := numGoroutines * numOperations
    assert.Equal(t, int64(expectedSets), stats.Sets)
}
```

## ğŸ“‹ éƒ¨ç½²æ£€æŸ¥æ¸…å•

### ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²å‰æ£€æŸ¥

- [ ] è¿æ¥æ± é…ç½®å·²ä¼˜åŒ–
- [ ] TTLç­–ç•¥å·²æ ¹æ®ä¸šåŠ¡è®¾å®š
- [ ] ç›‘æ§æŒ‡æ ‡å·²é…ç½®
- [ ] å‘Šè­¦é˜ˆå€¼å·²è®¾å®š
- [ ] é™çº§ç­–ç•¥å·²å®ç°
- [ ] å‹åŠ›æµ‹è¯•å·²é€šè¿‡
- [ ] æ–‡æ¡£å·²æ›´æ–°
- [ ] è¿ç»´æ‰‹å†Œå·²å‡†å¤‡

### ç›‘æ§æŒ‡æ ‡é…ç½®

- [ ] ç¼“å­˜å‘½ä¸­ç‡ (ç›®æ ‡ > 80%)
- [ ] å¹³å‡å»¶è¿Ÿ (ç›®æ ‡ < 5ms)
- [ ] é”™è¯¯ç‡ (ç›®æ ‡ < 1%)
- [ ] è¿æ¥æ± ä½¿ç”¨ç‡
- [ ] å†…å­˜ä½¿ç”¨ç‡
- [ ] QPSç»Ÿè®¡

### å‘Šè­¦é…ç½®

- [ ] å‘½ä¸­ç‡è¿‡ä½å‘Šè­¦
- [ ] å»¶è¿Ÿè¿‡é«˜å‘Šè­¦
- [ ] é”™è¯¯ç‡è¿‡é«˜å‘Šè­¦
- [ ] è¿æ¥æ•°å¼‚å¸¸å‘Šè­¦
- [ ] RedisæœåŠ¡ä¸å¯ç”¨å‘Šè­¦

## ğŸ”— ç›¸å…³èµ„æº

- [Day 5å­¦ä¹ æ€»ç»“](../day5-summary.md)
- [Rediså®˜æ–¹æœ€ä½³å®è·µ](https://redis.io/docs/latest/develop/use/patterns/)
- [Go Rediså®¢æˆ·ç«¯æ–‡æ¡£](https://redis.uptrace.dev/)
- [ç¼“å­˜è®¾è®¡æ¨¡å¼](https://docs.microsoft.com/en-us/azure/architecture/patterns/cache-aside) 